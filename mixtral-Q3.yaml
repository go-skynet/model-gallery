name: "mixtral-8x7B-Q3_K_M"

description: |
  This is a mixtral model

license: "https://www.apache.org/licenses/LICENSE-2.0"
urls:
- https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF

config_file: |
  name: mixtral-8x7B-Q3_K_M
  context_size: 4096
  f16: true
  mmap: true
  #gpu_layers: 90 # uncomment to offload all layers to GPU
  threads: 8
  parameters:
    model: mixtral-8x7b-instruct-v0.1.Q3_K_M.gguf
    temperature: 0.2
    top_k: 40
    top_p: 0.95
    frequency_penalty: 1.1
    batch: 512
    tfz: 1.0
  template:
    chat: mixtral-chat
    completion: mixtral-completion
  stopwords:
  - <|im_end|>

prompt_templates:
- name: "mixtral-chat"
  content: |
    [INST] {{.Input}} [/INST]
- name: "mixtral-completion"
  content: |
    [INST] {{.Input}} [/INST]
    
files:
- filename: "mixtral-8x7b-instruct-v0.1.Q3_K_M.gguf"
  sha256: "bd2e1499e68195f1a6ff151e6fa5c6632acc150b80cca4a3772cbb7ca59d44cd"
  uri: "https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF/resolve/main/mixtral-8x7b-instruct-v0.1.Q3_K_M.gguf"
