- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-7b.Q2_K.gguf
    template:
      chat: Kimiko
      completion: Kimiko
  description: TheBloke/Kimiko-7B-GGUF - llama configuration
  files:
  - filename: Kimiko.tmpl
    sha256: aa2cf15eba3b0f445330773e72999a1ce4653ce1ed4f2de2dc30c22178f938c5
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Kimiko.tmpl
  - filename: kimiko-7b.Q2_K.gguf
    sha256: f5de6823bf78d8da792fe61c15ec55afc56142dcda44a97e76f7f02e540174ca
    uri: https://huggingface.co/TheBloke/Kimiko-7B-GGUF/resolve/main/kimiko-7b.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Kimiko-7B-GGUF__kimiko-7b.Q2_K.gguf
  tags:
  - transformers
  - llama
  - arxiv:1910.09700
  - base_model:nRuaif/Kimiko_7b
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-7b.Q3_K_L.gguf
    template:
      chat: Kimiko
      completion: Kimiko
  description: TheBloke/Kimiko-7B-GGUF - llama configuration
  files:
  - filename: Kimiko.tmpl
    sha256: aa2cf15eba3b0f445330773e72999a1ce4653ce1ed4f2de2dc30c22178f938c5
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Kimiko.tmpl
  - filename: kimiko-7b.Q3_K_L.gguf
    sha256: 12cd2c871db61dbf41a6aa710b7d3c33eed702e5333150703163672857b5b92d
    uri: 
      https://huggingface.co/TheBloke/Kimiko-7B-GGUF/resolve/main/kimiko-7b.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Kimiko-7B-GGUF__kimiko-7b.Q3_K_L.gguf
  tags:
  - transformers
  - llama
  - arxiv:1910.09700
  - base_model:nRuaif/Kimiko_7b
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-7b.Q3_K_M.gguf
    template:
      chat: Kimiko
      completion: Kimiko
  description: TheBloke/Kimiko-7B-GGUF - llama configuration
  files:
  - filename: Kimiko.tmpl
    sha256: aa2cf15eba3b0f445330773e72999a1ce4653ce1ed4f2de2dc30c22178f938c5
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Kimiko.tmpl
  - filename: kimiko-7b.Q3_K_M.gguf
    sha256: 8995e903b8402010a6cc3bee2b9caea40f2a8ee55d63699852606fac702240bb
    uri: 
      https://huggingface.co/TheBloke/Kimiko-7B-GGUF/resolve/main/kimiko-7b.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Kimiko-7B-GGUF__kimiko-7b.Q3_K_M.gguf
  tags:
  - transformers
  - llama
  - arxiv:1910.09700
  - base_model:nRuaif/Kimiko_7b
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-7b.Q3_K_S.gguf
    template:
      chat: Kimiko
      completion: Kimiko
  description: TheBloke/Kimiko-7B-GGUF - llama configuration
  files:
  - filename: Kimiko.tmpl
    sha256: aa2cf15eba3b0f445330773e72999a1ce4653ce1ed4f2de2dc30c22178f938c5
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Kimiko.tmpl
  - filename: kimiko-7b.Q3_K_S.gguf
    sha256: 046c481001bc914e97fd610f8570c39fbaae8d1624d7da54862e1b81fd29ad2b
    uri: 
      https://huggingface.co/TheBloke/Kimiko-7B-GGUF/resolve/main/kimiko-7b.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Kimiko-7B-GGUF__kimiko-7b.Q3_K_S.gguf
  tags:
  - transformers
  - llama
  - arxiv:1910.09700
  - base_model:nRuaif/Kimiko_7b
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-7b.Q4_0.gguf
    template:
      chat: Kimiko
      completion: Kimiko
  description: TheBloke/Kimiko-7B-GGUF - llama configuration
  files:
  - filename: Kimiko.tmpl
    sha256: aa2cf15eba3b0f445330773e72999a1ce4653ce1ed4f2de2dc30c22178f938c5
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Kimiko.tmpl
  - filename: kimiko-7b.Q4_0.gguf
    sha256: 997ab86a9673b68877e81e2623ebfdea49ab156b044ee86c896e5610c01f4274
    uri: https://huggingface.co/TheBloke/Kimiko-7B-GGUF/resolve/main/kimiko-7b.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Kimiko-7B-GGUF__kimiko-7b.Q4_0.gguf
  tags:
  - transformers
  - llama
  - arxiv:1910.09700
  - base_model:nRuaif/Kimiko_7b
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-7b.Q4_K_M.gguf
    template:
      chat: Kimiko
      completion: Kimiko
  description: TheBloke/Kimiko-7B-GGUF - llama configuration
  files:
  - filename: Kimiko.tmpl
    sha256: aa2cf15eba3b0f445330773e72999a1ce4653ce1ed4f2de2dc30c22178f938c5
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Kimiko.tmpl
  - filename: kimiko-7b.Q4_K_M.gguf
    sha256: a3357af0364df4ecebc3d5a867d9a9bb2d22cc841cb52a18294d9168860c2f8f
    uri: 
      https://huggingface.co/TheBloke/Kimiko-7B-GGUF/resolve/main/kimiko-7b.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Kimiko-7B-GGUF__kimiko-7b.Q4_K_M.gguf
  tags:
  - transformers
  - llama
  - arxiv:1910.09700
  - base_model:nRuaif/Kimiko_7b
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-7b.Q4_K_S.gguf
    template:
      chat: Kimiko
      completion: Kimiko
  description: TheBloke/Kimiko-7B-GGUF - llama configuration
  files:
  - filename: Kimiko.tmpl
    sha256: aa2cf15eba3b0f445330773e72999a1ce4653ce1ed4f2de2dc30c22178f938c5
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Kimiko.tmpl
  - filename: kimiko-7b.Q4_K_S.gguf
    sha256: d1b17ad4a1e75f9c358cdd290189f64d02014d49522b5993de00c3cf416e247c
    uri: 
      https://huggingface.co/TheBloke/Kimiko-7B-GGUF/resolve/main/kimiko-7b.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Kimiko-7B-GGUF__kimiko-7b.Q4_K_S.gguf
  tags:
  - transformers
  - llama
  - arxiv:1910.09700
  - base_model:nRuaif/Kimiko_7b
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-7b.Q5_0.gguf
    template:
      chat: Kimiko
      completion: Kimiko
  description: TheBloke/Kimiko-7B-GGUF - llama configuration
  files:
  - filename: Kimiko.tmpl
    sha256: aa2cf15eba3b0f445330773e72999a1ce4653ce1ed4f2de2dc30c22178f938c5
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Kimiko.tmpl
  - filename: kimiko-7b.Q5_0.gguf
    sha256: 7f1fcc9a24d479bceefce1c0af083dcbb8156b2a36ea4d95ebfa0bdb5f3656c9
    uri: https://huggingface.co/TheBloke/Kimiko-7B-GGUF/resolve/main/kimiko-7b.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Kimiko-7B-GGUF__kimiko-7b.Q5_0.gguf
  tags:
  - transformers
  - llama
  - arxiv:1910.09700
  - base_model:nRuaif/Kimiko_7b
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-7b.Q5_K_M.gguf
    template:
      chat: Kimiko
      completion: Kimiko
  description: TheBloke/Kimiko-7B-GGUF - llama configuration
  files:
  - filename: Kimiko.tmpl
    sha256: aa2cf15eba3b0f445330773e72999a1ce4653ce1ed4f2de2dc30c22178f938c5
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Kimiko.tmpl
  - filename: kimiko-7b.Q5_K_M.gguf
    sha256: bcce7db902bcef43554892da57809d57c3c753ea6b17fccc58be46942925c992
    uri: 
      https://huggingface.co/TheBloke/Kimiko-7B-GGUF/resolve/main/kimiko-7b.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Kimiko-7B-GGUF__kimiko-7b.Q5_K_M.gguf
  tags:
  - transformers
  - llama
  - arxiv:1910.09700
  - base_model:nRuaif/Kimiko_7b
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-7b.Q5_K_S.gguf
    template:
      chat: Kimiko
      completion: Kimiko
  description: TheBloke/Kimiko-7B-GGUF - llama configuration
  files:
  - filename: Kimiko.tmpl
    sha256: aa2cf15eba3b0f445330773e72999a1ce4653ce1ed4f2de2dc30c22178f938c5
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Kimiko.tmpl
  - filename: kimiko-7b.Q5_K_S.gguf
    sha256: ee5392c8543a16cbd03ed04e2c2964e3edf9802c424cd0ac09f69a94f4717b1c
    uri: 
      https://huggingface.co/TheBloke/Kimiko-7B-GGUF/resolve/main/kimiko-7b.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Kimiko-7B-GGUF__kimiko-7b.Q5_K_S.gguf
  tags:
  - transformers
  - llama
  - arxiv:1910.09700
  - base_model:nRuaif/Kimiko_7b
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-7b.Q6_K.gguf
    template:
      chat: Kimiko
      completion: Kimiko
  description: TheBloke/Kimiko-7B-GGUF - llama configuration
  files:
  - filename: Kimiko.tmpl
    sha256: aa2cf15eba3b0f445330773e72999a1ce4653ce1ed4f2de2dc30c22178f938c5
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Kimiko.tmpl
  - filename: kimiko-7b.Q6_K.gguf
    sha256: 77bef9130e46d8ffbc8a988e32c848be0087e79842ff77aefa59a8ad7857b5e5
    uri: https://huggingface.co/TheBloke/Kimiko-7B-GGUF/resolve/main/kimiko-7b.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Kimiko-7B-GGUF__kimiko-7b.Q6_K.gguf
  tags:
  - transformers
  - llama
  - arxiv:1910.09700
  - base_model:nRuaif/Kimiko_7b
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-7B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: kimiko-7b.Q8_0.gguf
    template:
      chat: Kimiko
      completion: Kimiko
  description: TheBloke/Kimiko-7B-GGUF - llama configuration
  files:
  - filename: Kimiko.tmpl
    sha256: aa2cf15eba3b0f445330773e72999a1ce4653ce1ed4f2de2dc30c22178f938c5
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Kimiko.tmpl
  - filename: kimiko-7b.Q8_0.gguf
    sha256: 72ad9b7733a0dd2cd77a611b695f78b3dbc6b6079b987978911fff9969e39c7d
    uri: https://huggingface.co/TheBloke/Kimiko-7B-GGUF/resolve/main/kimiko-7b.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Kimiko-7B-GGUF__kimiko-7b.Q8_0.gguf
  tags:
  - transformers
  - llama
  - arxiv:1910.09700
  - base_model:nRuaif/Kimiko_7b
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Kimiko-7B-GGUF
