- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: WizardLM-Uncensored-SuperCOT-Storytelling.Q2_K.gguf
    template:
      chat: Vicuna-Short
      completion: Vicuna-Short
  description: TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF - llama
    configuration
  files:
  - filename: Vicuna-Short.tmpl
    sha256: 4f2e4df7367ee6f177bcb043807911366ca9b4d17bed618d08f34ebb89c50117
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna-Short.tmpl
  - filename: WizardLM-Uncensored-SuperCOT-Storytelling.Q2_K.gguf
    sha256: eaa7a4440465bbf5269d505ba40f167d8126f385810d59e48f921975973905d4
    uri: 
      https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF/resolve/main/WizardLM-Uncensored-SuperCOT-Storytelling.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: 
    TheBloke__WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF__WizardLM-Uncensored-SuperCOT-Storytelling.Q2_K.gguf
  tags:
  - transformers
  - llama
  - base_model:Monero/WizardLM-Uncensored-SuperCOT-StoryTelling-30b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: WizardLM-Uncensored-SuperCOT-Storytelling.Q3_K_L.gguf
    template:
      chat: Vicuna-Short
      completion: Vicuna-Short
  description: TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF - llama
    configuration
  files:
  - filename: Vicuna-Short.tmpl
    sha256: 4f2e4df7367ee6f177bcb043807911366ca9b4d17bed618d08f34ebb89c50117
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna-Short.tmpl
  - filename: WizardLM-Uncensored-SuperCOT-Storytelling.Q3_K_L.gguf
    sha256: 8403cb84449b215adaa278b9c68b35c74c15f56ae12388c03f66baf330f7e13e
    uri: 
      https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF/resolve/main/WizardLM-Uncensored-SuperCOT-Storytelling.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: 
    TheBloke__WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF__WizardLM-Uncensored-SuperCOT-Storytelling.Q3_K_L.gguf
  tags:
  - transformers
  - llama
  - base_model:Monero/WizardLM-Uncensored-SuperCOT-StoryTelling-30b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: WizardLM-Uncensored-SuperCOT-Storytelling.Q3_K_M.gguf
    template:
      chat: Vicuna-Short
      completion: Vicuna-Short
  description: TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF - llama
    configuration
  files:
  - filename: Vicuna-Short.tmpl
    sha256: 4f2e4df7367ee6f177bcb043807911366ca9b4d17bed618d08f34ebb89c50117
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna-Short.tmpl
  - filename: WizardLM-Uncensored-SuperCOT-Storytelling.Q3_K_M.gguf
    sha256: fd4da0c837ff0662ecbf7802a58a65e79a7d3af65408da344c786989002aa1f7
    uri: 
      https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF/resolve/main/WizardLM-Uncensored-SuperCOT-Storytelling.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: 
    TheBloke__WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF__WizardLM-Uncensored-SuperCOT-Storytelling.Q3_K_M.gguf
  tags:
  - transformers
  - llama
  - base_model:Monero/WizardLM-Uncensored-SuperCOT-StoryTelling-30b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: WizardLM-Uncensored-SuperCOT-Storytelling.Q3_K_S.gguf
    template:
      chat: Vicuna-Short
      completion: Vicuna-Short
  description: TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF - llama
    configuration
  files:
  - filename: Vicuna-Short.tmpl
    sha256: 4f2e4df7367ee6f177bcb043807911366ca9b4d17bed618d08f34ebb89c50117
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna-Short.tmpl
  - filename: WizardLM-Uncensored-SuperCOT-Storytelling.Q3_K_S.gguf
    sha256: 2d15a8b58d94cba5b8f05e2e9092e917c7ec965dbd4b1f9afcdb5e52ae7c658c
    uri: 
      https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF/resolve/main/WizardLM-Uncensored-SuperCOT-Storytelling.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: 
    TheBloke__WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF__WizardLM-Uncensored-SuperCOT-Storytelling.Q3_K_S.gguf
  tags:
  - transformers
  - llama
  - base_model:Monero/WizardLM-Uncensored-SuperCOT-StoryTelling-30b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: WizardLM-Uncensored-SuperCOT-Storytelling.Q4_0.gguf
    template:
      chat: Vicuna-Short
      completion: Vicuna-Short
  description: TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF - llama
    configuration
  files:
  - filename: Vicuna-Short.tmpl
    sha256: 4f2e4df7367ee6f177bcb043807911366ca9b4d17bed618d08f34ebb89c50117
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna-Short.tmpl
  - filename: WizardLM-Uncensored-SuperCOT-Storytelling.Q4_0.gguf
    sha256: 48e42d0284a7cd030ee08e69fa748f8b7ee95146989af544fd4191b33f1991ce
    uri: 
      https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF/resolve/main/WizardLM-Uncensored-SuperCOT-Storytelling.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: 
    TheBloke__WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF__WizardLM-Uncensored-SuperCOT-Storytelling.Q4_0.gguf
  tags:
  - transformers
  - llama
  - base_model:Monero/WizardLM-Uncensored-SuperCOT-StoryTelling-30b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: WizardLM-Uncensored-SuperCOT-Storytelling.Q4_K_M.gguf
    template:
      chat: Vicuna-Short
      completion: Vicuna-Short
  description: TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF - llama
    configuration
  files:
  - filename: Vicuna-Short.tmpl
    sha256: 4f2e4df7367ee6f177bcb043807911366ca9b4d17bed618d08f34ebb89c50117
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna-Short.tmpl
  - filename: WizardLM-Uncensored-SuperCOT-Storytelling.Q4_K_M.gguf
    sha256: 09ebae7ca3342ea84338818c8014f66a6cc0d2e01f669243a9ac4487713178df
    uri: 
      https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF/resolve/main/WizardLM-Uncensored-SuperCOT-Storytelling.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: 
    TheBloke__WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF__WizardLM-Uncensored-SuperCOT-Storytelling.Q4_K_M.gguf
  tags:
  - transformers
  - llama
  - base_model:Monero/WizardLM-Uncensored-SuperCOT-StoryTelling-30b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: WizardLM-Uncensored-SuperCOT-Storytelling.Q4_K_S.gguf
    template:
      chat: Vicuna-Short
      completion: Vicuna-Short
  description: TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF - llama
    configuration
  files:
  - filename: Vicuna-Short.tmpl
    sha256: 4f2e4df7367ee6f177bcb043807911366ca9b4d17bed618d08f34ebb89c50117
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna-Short.tmpl
  - filename: WizardLM-Uncensored-SuperCOT-Storytelling.Q4_K_S.gguf
    sha256: 86ecbe6742f8794cf59e73985d6c19eca639d2342e8a59e8e142d99fbf81fdf2
    uri: 
      https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF/resolve/main/WizardLM-Uncensored-SuperCOT-Storytelling.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: 
    TheBloke__WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF__WizardLM-Uncensored-SuperCOT-Storytelling.Q4_K_S.gguf
  tags:
  - transformers
  - llama
  - base_model:Monero/WizardLM-Uncensored-SuperCOT-StoryTelling-30b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: WizardLM-Uncensored-SuperCOT-Storytelling.Q5_0.gguf
    template:
      chat: Vicuna-Short
      completion: Vicuna-Short
  description: TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF - llama
    configuration
  files:
  - filename: Vicuna-Short.tmpl
    sha256: 4f2e4df7367ee6f177bcb043807911366ca9b4d17bed618d08f34ebb89c50117
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna-Short.tmpl
  - filename: WizardLM-Uncensored-SuperCOT-Storytelling.Q5_0.gguf
    sha256: 13e3d59cfa8fc4a7807155702744f7f8600858061e8bf2e39474c49d67828dbb
    uri: 
      https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF/resolve/main/WizardLM-Uncensored-SuperCOT-Storytelling.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: 
    TheBloke__WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF__WizardLM-Uncensored-SuperCOT-Storytelling.Q5_0.gguf
  tags:
  - transformers
  - llama
  - base_model:Monero/WizardLM-Uncensored-SuperCOT-StoryTelling-30b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: WizardLM-Uncensored-SuperCOT-Storytelling.Q5_K_M.gguf
    template:
      chat: Vicuna-Short
      completion: Vicuna-Short
  description: TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF - llama
    configuration
  files:
  - filename: Vicuna-Short.tmpl
    sha256: 4f2e4df7367ee6f177bcb043807911366ca9b4d17bed618d08f34ebb89c50117
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna-Short.tmpl
  - filename: WizardLM-Uncensored-SuperCOT-Storytelling.Q5_K_M.gguf
    sha256: 35d6be323b5efb649fa7437abb6adaa6fde22da9d1486b8c40c04999919327b2
    uri: 
      https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF/resolve/main/WizardLM-Uncensored-SuperCOT-Storytelling.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: 
    TheBloke__WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF__WizardLM-Uncensored-SuperCOT-Storytelling.Q5_K_M.gguf
  tags:
  - transformers
  - llama
  - base_model:Monero/WizardLM-Uncensored-SuperCOT-StoryTelling-30b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: WizardLM-Uncensored-SuperCOT-Storytelling.Q5_K_S.gguf
    template:
      chat: Vicuna-Short
      completion: Vicuna-Short
  description: TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF - llama
    configuration
  files:
  - filename: Vicuna-Short.tmpl
    sha256: 4f2e4df7367ee6f177bcb043807911366ca9b4d17bed618d08f34ebb89c50117
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna-Short.tmpl
  - filename: WizardLM-Uncensored-SuperCOT-Storytelling.Q5_K_S.gguf
    sha256: 398a876a8d69153d1699444706240be0e4bbd85c4e3015369f0b2c12c54237fc
    uri: 
      https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF/resolve/main/WizardLM-Uncensored-SuperCOT-Storytelling.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: 
    TheBloke__WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF__WizardLM-Uncensored-SuperCOT-Storytelling.Q5_K_S.gguf
  tags:
  - transformers
  - llama
  - base_model:Monero/WizardLM-Uncensored-SuperCOT-StoryTelling-30b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: WizardLM-Uncensored-SuperCOT-Storytelling.Q6_K.gguf
    template:
      chat: Vicuna-Short
      completion: Vicuna-Short
  description: TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF - llama
    configuration
  files:
  - filename: Vicuna-Short.tmpl
    sha256: 4f2e4df7367ee6f177bcb043807911366ca9b4d17bed618d08f34ebb89c50117
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna-Short.tmpl
  - filename: WizardLM-Uncensored-SuperCOT-Storytelling.Q6_K.gguf
    sha256: 487111a4acf26b0f6e215f6b49383f702eb8d0108d129e53ebac3c31c7963a75
    uri: 
      https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF/resolve/main/WizardLM-Uncensored-SuperCOT-Storytelling.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: 
    TheBloke__WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF__WizardLM-Uncensored-SuperCOT-Storytelling.Q6_K.gguf
  tags:
  - transformers
  - llama
  - base_model:Monero/WizardLM-Uncensored-SuperCOT-StoryTelling-30b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: WizardLM-Uncensored-SuperCOT-Storytelling.Q8_0.gguf
    template:
      chat: Vicuna-Short
      completion: Vicuna-Short
  description: TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF - llama
    configuration
  files:
  - filename: Vicuna-Short.tmpl
    sha256: 4f2e4df7367ee6f177bcb043807911366ca9b4d17bed618d08f34ebb89c50117
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna-Short.tmpl
  - filename: WizardLM-Uncensored-SuperCOT-Storytelling.Q8_0.gguf
    sha256: 6a2d2cb5424688a4ca4d69e87fca7cb75c2fc6dae164260e8e65cd369620a94b
    uri: 
      https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF/resolve/main/WizardLM-Uncensored-SuperCOT-Storytelling.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: 
    TheBloke__WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF__WizardLM-Uncensored-SuperCOT-Storytelling.Q8_0.gguf
  tags:
  - transformers
  - llama
  - base_model:Monero/WizardLM-Uncensored-SuperCOT-StoryTelling-30b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF
