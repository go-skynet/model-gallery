- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: dolphin-llama-13b.Q2_K.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Dolphin-Llama-13B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: dolphin-llama-13b.Q2_K.gguf
    sha256: a2fc0403c4979660ad604dc28887d20df1657a96ca7ace416a003dab843d4eaa
    uri: 
      https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF/resolve/main/dolphin-llama-13b.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__Dolphin-Llama-13B-GGUF__dolphin-llama-13b.Q2_K.gguf
  tags:
  - transformers
  - llama
  - base_model:ehartford/dolphin-llama-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: dolphin-llama-13b.Q3_K_L.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Dolphin-Llama-13B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: dolphin-llama-13b.Q3_K_L.gguf
    sha256: a21022f32eca742e9471218f0a910cd9989eba202005f2cd2d270cef8bdf580b
    uri: 
      https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF/resolve/main/dolphin-llama-13b.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__Dolphin-Llama-13B-GGUF__dolphin-llama-13b.Q3_K_L.gguf
  tags:
  - transformers
  - llama
  - base_model:ehartford/dolphin-llama-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: dolphin-llama-13b.Q3_K_M.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Dolphin-Llama-13B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: dolphin-llama-13b.Q3_K_M.gguf
    sha256: a95a38aab2ddcc7f04c49d3a03fc8a373d6c9b07775ed3ec863f0231c7b85a88
    uri: 
      https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF/resolve/main/dolphin-llama-13b.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__Dolphin-Llama-13B-GGUF__dolphin-llama-13b.Q3_K_M.gguf
  tags:
  - transformers
  - llama
  - base_model:ehartford/dolphin-llama-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: dolphin-llama-13b.Q3_K_S.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Dolphin-Llama-13B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: dolphin-llama-13b.Q3_K_S.gguf
    sha256: 241d1364cced7a16c75b1ed29bc0cbe7005d21a467d37963855eb6c8740f0ef6
    uri: 
      https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF/resolve/main/dolphin-llama-13b.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__Dolphin-Llama-13B-GGUF__dolphin-llama-13b.Q3_K_S.gguf
  tags:
  - transformers
  - llama
  - base_model:ehartford/dolphin-llama-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: dolphin-llama-13b.Q4_0.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Dolphin-Llama-13B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: dolphin-llama-13b.Q4_0.gguf
    sha256: 0d91eff1ef544f08289555582515da0ade418fb6afc0a0635ce0970a98a2d262
    uri: 
      https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF/resolve/main/dolphin-llama-13b.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__Dolphin-Llama-13B-GGUF__dolphin-llama-13b.Q4_0.gguf
  tags:
  - transformers
  - llama
  - base_model:ehartford/dolphin-llama-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: dolphin-llama-13b.Q4_K_M.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Dolphin-Llama-13B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: dolphin-llama-13b.Q4_K_M.gguf
    sha256: a2ae3033d4188bc75406b23c80c8830630e76fa74dd5d874e50e52cc74c4a8e4
    uri: 
      https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF/resolve/main/dolphin-llama-13b.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__Dolphin-Llama-13B-GGUF__dolphin-llama-13b.Q4_K_M.gguf
  tags:
  - transformers
  - llama
  - base_model:ehartford/dolphin-llama-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: dolphin-llama-13b.Q4_K_S.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Dolphin-Llama-13B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: dolphin-llama-13b.Q4_K_S.gguf
    sha256: e44cd4e1083b8ba031edbf428f67ddada971d4ddbdadda0d18091c5feabf2a2c
    uri: 
      https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF/resolve/main/dolphin-llama-13b.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__Dolphin-Llama-13B-GGUF__dolphin-llama-13b.Q4_K_S.gguf
  tags:
  - transformers
  - llama
  - base_model:ehartford/dolphin-llama-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: dolphin-llama-13b.Q5_0.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Dolphin-Llama-13B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: dolphin-llama-13b.Q5_0.gguf
    sha256: 7eb0b9b68cbee65cca7bf0ea2ef1650fbf6f6aa3f286e444f097a657153ab8f5
    uri: 
      https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF/resolve/main/dolphin-llama-13b.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__Dolphin-Llama-13B-GGUF__dolphin-llama-13b.Q5_0.gguf
  tags:
  - transformers
  - llama
  - base_model:ehartford/dolphin-llama-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: dolphin-llama-13b.Q5_K_M.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Dolphin-Llama-13B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: dolphin-llama-13b.Q5_K_M.gguf
    sha256: 9ffcf2d065dfb165b3a110134b1acf838eaa434be65f080bfe23ff1a263b64ea
    uri: 
      https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF/resolve/main/dolphin-llama-13b.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__Dolphin-Llama-13B-GGUF__dolphin-llama-13b.Q5_K_M.gguf
  tags:
  - transformers
  - llama
  - base_model:ehartford/dolphin-llama-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: dolphin-llama-13b.Q5_K_S.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Dolphin-Llama-13B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: dolphin-llama-13b.Q5_K_S.gguf
    sha256: 8445adf2eed1378e7233f60c9b562bd8070ac3f0f5d02f891993d476fdd8a4eb
    uri: 
      https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF/resolve/main/dolphin-llama-13b.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__Dolphin-Llama-13B-GGUF__dolphin-llama-13b.Q5_K_S.gguf
  tags:
  - transformers
  - llama
  - base_model:ehartford/dolphin-llama-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: dolphin-llama-13b.Q6_K.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Dolphin-Llama-13B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: dolphin-llama-13b.Q6_K.gguf
    sha256: ea8b7f8c688afd49c5bf0d14f0298c207db2f829229f4fa5a506270edeeada5a
    uri: 
      https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF/resolve/main/dolphin-llama-13b.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__Dolphin-Llama-13B-GGUF__dolphin-llama-13b.Q6_K.gguf
  tags:
  - transformers
  - llama
  - base_model:ehartford/dolphin-llama-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: dolphin-llama-13b.Q8_0.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Dolphin-Llama-13B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: dolphin-llama-13b.Q8_0.gguf
    sha256: 47d867de2f5ebad9222f50ea482c4a5e8501432b3cfd3a8fd6f16154ad24f54b
    uri: 
      https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF/resolve/main/dolphin-llama-13b.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__Dolphin-Llama-13B-GGUF__dolphin-llama-13b.Q8_0.gguf
  tags:
  - transformers
  - llama
  - base_model:ehartford/dolphin-llama-13b
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Dolphin-Llama-13B-GGUF
