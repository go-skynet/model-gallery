- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q2_K.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q2_K.bin
    sha256: 7eb73edcc00f04c2b833d207494622de26e67fd3bb09b15e8a2a145fca41fff1
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q2_K.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q2_K.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q3_K_L.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q3_K_L.bin
    sha256: 2f9c0c54ce2c3d35a6a20081d550c2ee06979fbfdfd17b6d6bdb5f7db6d8b248
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q3_K_L.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q3_K_L.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q3_K_M.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q3_K_M.bin
    sha256: a966ac5b7f64b773b4c4d189b6751674877554dbd8bf4efa1cf31feabc5bc780
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q3_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q3_K_M.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q3_K_S.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q3_K_S.bin
    sha256: f99932839aec33ffa9ffeabc46fa367a50b34487d83efb71a3200cbbadd2181b
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q3_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q3_K_S.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q4_0.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q4_0.bin
    sha256: f90e7006936d1b3bc1dc7015f3e3be3e46c0cdc107d87ecfef430dc3633e8937
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q4_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q4_0.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q4_1.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q4_1.bin
    sha256: b4f6c2ac8c29e2d7dbcabe5d3e09ae0fe0bba4efabd5feda01a9c09217710f1f
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q4_1.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q4_1.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q4_K_M.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q4_K_M.bin
    sha256: 0d1fce757c8bcd5ed1cc30ea8ba181390321fd4199f9c774459f514669df7f25
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q4_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q4_K_M.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q4_K_S.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q4_K_S.bin
    sha256: a48d2c247b76948a8b1f2198d0680cd9ebaafd40436a9b888b1f37a31d06cae3
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q4_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q4_K_S.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q5_0.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q5_0.bin
    sha256: 41d8bc437d8c5e6ceb23646e10b4db4031c23c315bf02d66d0c4857b3bc55ad8
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q5_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q5_0.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q5_1.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q5_1.bin
    sha256: 7b98bd2bfa6e1e0e7bb805b651adea07804dd20d9574a8ac950df451c5b45ee6
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q5_1.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q5_1.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q5_K_M.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q5_K_M.bin
    sha256: 94970d6a06e5aa49d84a8107da692ce1d07bcef438b2273260b713348c1473ab
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q5_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q5_K_M.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q5_K_S.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q5_K_S.bin
    sha256: e544fc09ad2c54c997e1ae371b36dc64ce1d0ad7f2697d0095c1870afe928a1a
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q5_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q5_K_S.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q6_K.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q6_K.bin
    sha256: c79faddc179f8f561037154d2e597cbb80a2ea0a2fcedf1ba4165778252fc9b1
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q6_K.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q6_K.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q8_0.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q8_0.bin
    sha256: 23439c1a67003078d257cc9fc1ead9fa7cd749352ae4277bae19fb7e470b65bc
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q8_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q8_0.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q2_K.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q2_K.bin
    sha256: 7eb73edcc00f04c2b833d207494622de26e67fd3bb09b15e8a2a145fca41fff1
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q2_K.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q2_K.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q3_K_L.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q3_K_L.bin
    sha256: 2f9c0c54ce2c3d35a6a20081d550c2ee06979fbfdfd17b6d6bdb5f7db6d8b248
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q3_K_L.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q3_K_L.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q3_K_M.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q3_K_M.bin
    sha256: a966ac5b7f64b773b4c4d189b6751674877554dbd8bf4efa1cf31feabc5bc780
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q3_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q3_K_M.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q3_K_S.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q3_K_S.bin
    sha256: f99932839aec33ffa9ffeabc46fa367a50b34487d83efb71a3200cbbadd2181b
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q3_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q3_K_S.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q4_0.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q4_0.bin
    sha256: f90e7006936d1b3bc1dc7015f3e3be3e46c0cdc107d87ecfef430dc3633e8937
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q4_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q4_0.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q4_1.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q4_1.bin
    sha256: b4f6c2ac8c29e2d7dbcabe5d3e09ae0fe0bba4efabd5feda01a9c09217710f1f
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q4_1.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q4_1.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q4_K_M.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q4_K_M.bin
    sha256: 0d1fce757c8bcd5ed1cc30ea8ba181390321fd4199f9c774459f514669df7f25
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q4_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q4_K_M.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q4_K_S.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q4_K_S.bin
    sha256: a48d2c247b76948a8b1f2198d0680cd9ebaafd40436a9b888b1f37a31d06cae3
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q4_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q4_K_S.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q5_0.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q5_0.bin
    sha256: 41d8bc437d8c5e6ceb23646e10b4db4031c23c315bf02d66d0c4857b3bc55ad8
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q5_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q5_0.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q5_1.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q5_1.bin
    sha256: 7b98bd2bfa6e1e0e7bb805b651adea07804dd20d9574a8ac950df451c5b45ee6
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q5_1.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q5_1.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q5_K_M.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q5_K_M.bin
    sha256: 94970d6a06e5aa49d84a8107da692ce1d07bcef438b2273260b713348c1473ab
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q5_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q5_K_M.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q5_K_S.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q5_K_S.bin
    sha256: e544fc09ad2c54c997e1ae371b36dc64ce1d0ad7f2697d0095c1870afe928a1a
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q5_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q5_K_S.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q6_K.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q6_K.bin
    sha256: c79faddc179f8f561037154d2e597cbb80a2ea0a2fcedf1ba4165778252fc9b1
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q6_K.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q6_K.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: qcammel-13.ggmlv3.q8_0.bin
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGML - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.ggmlv3.q8_0.bin
    sha256: 23439c1a67003078d257cc9fc1ead9fa7cd749352ae4277bae19fb7e470b65bc
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGML/resolve/main/qcammel-13.ggmlv3.q8_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__qCammel-13-GGML__qcammel-13.ggmlv3.q8_0.bin
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGML
