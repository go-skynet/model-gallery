- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-7b-uncensored.Q2_K.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Guanaco-7B-Uncensored-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: guanaco-7b-uncensored.Q2_K.gguf
    sha256: 0b5af9ec80b96c094d5c65100fa1d7f4875765bb1f3d1a3bdc862f327e3d45f5
    uri: 
      https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF/resolve/main/guanaco-7b-uncensored.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: TheBloke__Guanaco-7B-Uncensored-GGUF__guanaco-7b-uncensored.Q2_K.gguf
  tags:
  - transformers
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-7b-Uncensored
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-7b-uncensored.Q3_K_L.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Guanaco-7B-Uncensored-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: guanaco-7b-uncensored.Q3_K_L.gguf
    sha256: 84ec5df2f82267ae05fb52b469fef3fa8b5e2fc9b63578055fc13887aaf9b341
    uri: 
      https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF/resolve/main/guanaco-7b-uncensored.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: TheBloke__Guanaco-7B-Uncensored-GGUF__guanaco-7b-uncensored.Q3_K_L.gguf
  tags:
  - transformers
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-7b-Uncensored
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-7b-uncensored.Q3_K_M.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Guanaco-7B-Uncensored-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: guanaco-7b-uncensored.Q3_K_M.gguf
    sha256: a4ceccb4531addd8e6a6d2e0260d98552d70b5b4becc00b23852c06d002a5488
    uri: 
      https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF/resolve/main/guanaco-7b-uncensored.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: TheBloke__Guanaco-7B-Uncensored-GGUF__guanaco-7b-uncensored.Q3_K_M.gguf
  tags:
  - transformers
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-7b-Uncensored
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-7b-uncensored.Q3_K_S.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Guanaco-7B-Uncensored-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: guanaco-7b-uncensored.Q3_K_S.gguf
    sha256: 7fffd0b958ad30a8ea35f632903b8aced5bf5ebd302836edbd0ccca3b3c7f5f8
    uri: 
      https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF/resolve/main/guanaco-7b-uncensored.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: TheBloke__Guanaco-7B-Uncensored-GGUF__guanaco-7b-uncensored.Q3_K_S.gguf
  tags:
  - transformers
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-7b-Uncensored
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-7b-uncensored.Q4_0.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Guanaco-7B-Uncensored-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: guanaco-7b-uncensored.Q4_0.gguf
    sha256: 5f4e5a138ca308d998b64f32eefb92e461cbebc0f6bf292338969429e388f3e3
    uri: 
      https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF/resolve/main/guanaco-7b-uncensored.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: TheBloke__Guanaco-7B-Uncensored-GGUF__guanaco-7b-uncensored.Q4_0.gguf
  tags:
  - transformers
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-7b-Uncensored
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-7b-uncensored.Q4_K_M.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Guanaco-7B-Uncensored-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: guanaco-7b-uncensored.Q4_K_M.gguf
    sha256: 33d7210b9ba4f403307222161add0475bfea7305813a5f42626b5a6ea6914914
    uri: 
      https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF/resolve/main/guanaco-7b-uncensored.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: TheBloke__Guanaco-7B-Uncensored-GGUF__guanaco-7b-uncensored.Q4_K_M.gguf
  tags:
  - transformers
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-7b-Uncensored
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-7b-uncensored.Q4_K_S.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Guanaco-7B-Uncensored-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: guanaco-7b-uncensored.Q4_K_S.gguf
    sha256: 45bc9dadc8b75370f37c7cb3b292bab12ff6f4e5e84387d2102bb6ec488fafda
    uri: 
      https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF/resolve/main/guanaco-7b-uncensored.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: TheBloke__Guanaco-7B-Uncensored-GGUF__guanaco-7b-uncensored.Q4_K_S.gguf
  tags:
  - transformers
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-7b-Uncensored
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-7b-uncensored.Q5_0.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Guanaco-7B-Uncensored-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: guanaco-7b-uncensored.Q5_0.gguf
    sha256: 08e1e541a84f16b95acc4f6162e8c295d374e962828a5cbb4bf08b003312153c
    uri: 
      https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF/resolve/main/guanaco-7b-uncensored.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: TheBloke__Guanaco-7B-Uncensored-GGUF__guanaco-7b-uncensored.Q5_0.gguf
  tags:
  - transformers
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-7b-Uncensored
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-7b-uncensored.Q5_K_M.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Guanaco-7B-Uncensored-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: guanaco-7b-uncensored.Q5_K_M.gguf
    sha256: 5360a4c811749e2ec4ed0117f263ff61598fcb9238400d81ff6a7049e0ba6052
    uri: 
      https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF/resolve/main/guanaco-7b-uncensored.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: TheBloke__Guanaco-7B-Uncensored-GGUF__guanaco-7b-uncensored.Q5_K_M.gguf
  tags:
  - transformers
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-7b-Uncensored
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-7b-uncensored.Q5_K_S.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Guanaco-7B-Uncensored-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: guanaco-7b-uncensored.Q5_K_S.gguf
    sha256: 5ab1edc6d540ee9b7366079413d936ab691a78f49e46e7f0c4eccb7594ea7275
    uri: 
      https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF/resolve/main/guanaco-7b-uncensored.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: TheBloke__Guanaco-7B-Uncensored-GGUF__guanaco-7b-uncensored.Q5_K_S.gguf
  tags:
  - transformers
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-7b-Uncensored
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-7b-uncensored.Q6_K.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Guanaco-7B-Uncensored-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: guanaco-7b-uncensored.Q6_K.gguf
    sha256: 9b7c4b66f8ff1ced67c81b55b53613db85c94e0cdd4eb290bff9ce31db493454
    uri: 
      https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF/resolve/main/guanaco-7b-uncensored.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: TheBloke__Guanaco-7B-Uncensored-GGUF__guanaco-7b-uncensored.Q6_K.gguf
  tags:
  - transformers
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-7b-Uncensored
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: guanaco-7b-uncensored.Q8_0.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Guanaco-7B-Uncensored-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: guanaco-7b-uncensored.Q8_0.gguf
    sha256: 01191d965edf6a7ae31811ebf74b1e4e491eb294dee715007519f8d68c3906e5
    uri: 
      https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF/resolve/main/guanaco-7b-uncensored.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: apache-2.0
  name: TheBloke__Guanaco-7B-Uncensored-GGUF__guanaco-7b-uncensored.Q8_0.gguf
  tags:
  - transformers
  - llama
  - conversational
  - en
  - dataset:Fredithefish/openassistant-guanaco-unfiltered
  - base_model:Fredithefish/Guanaco-7b-Uncensored
  - license:apache-2.0
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Guanaco-7B-Uncensored-GGUF
