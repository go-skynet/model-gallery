- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: vicuna-33b-coder.Q2_K.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/vicuna-33B-coder-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: vicuna-33b-coder.Q2_K.gguf
    sha256: 76dbd0924c05a3287a2dece85ae450694e657566a086a9c66ec19498bd6aecd7
    uri: 
      https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF/resolve/main/vicuna-33b-coder.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__vicuna-33B-coder-GGUF__vicuna-33b-coder.Q2_K.gguf
  tags:
  - transformers
  - llama
  - code
  - arxiv:1910.09700
  - base_model:FelixChao/vicuna-33b-coder
  - license:other
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: vicuna-33b-coder.Q3_K_L.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/vicuna-33B-coder-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: vicuna-33b-coder.Q3_K_L.gguf
    sha256: 662f495d4159ba038048866b80677a8d7e6811459e65d8bdd0b569ef2f35b9be
    uri: 
      https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF/resolve/main/vicuna-33b-coder.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__vicuna-33B-coder-GGUF__vicuna-33b-coder.Q3_K_L.gguf
  tags:
  - transformers
  - llama
  - code
  - arxiv:1910.09700
  - base_model:FelixChao/vicuna-33b-coder
  - license:other
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: vicuna-33b-coder.Q3_K_M.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/vicuna-33B-coder-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: vicuna-33b-coder.Q3_K_M.gguf
    sha256: 41a45a23c00b50dd8ddabe6e693c0ad7de99438bac1f7b707a609dfbfb984d8f
    uri: 
      https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF/resolve/main/vicuna-33b-coder.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__vicuna-33B-coder-GGUF__vicuna-33b-coder.Q3_K_M.gguf
  tags:
  - transformers
  - llama
  - code
  - arxiv:1910.09700
  - base_model:FelixChao/vicuna-33b-coder
  - license:other
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: vicuna-33b-coder.Q3_K_S.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/vicuna-33B-coder-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: vicuna-33b-coder.Q3_K_S.gguf
    sha256: eeb619e80fcbf203cf017abe528291d6ebb9bb467608b7d0d8ebe412d768a1e0
    uri: 
      https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF/resolve/main/vicuna-33b-coder.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__vicuna-33B-coder-GGUF__vicuna-33b-coder.Q3_K_S.gguf
  tags:
  - transformers
  - llama
  - code
  - arxiv:1910.09700
  - base_model:FelixChao/vicuna-33b-coder
  - license:other
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: vicuna-33b-coder.Q4_0.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/vicuna-33B-coder-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: vicuna-33b-coder.Q4_0.gguf
    sha256: c3095cf8db2ee66870e79e04ec58f8bea02cc90329fd96981ac06b788bd4ef00
    uri: 
      https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF/resolve/main/vicuna-33b-coder.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__vicuna-33B-coder-GGUF__vicuna-33b-coder.Q4_0.gguf
  tags:
  - transformers
  - llama
  - code
  - arxiv:1910.09700
  - base_model:FelixChao/vicuna-33b-coder
  - license:other
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: vicuna-33b-coder.Q4_K_M.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/vicuna-33B-coder-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: vicuna-33b-coder.Q4_K_M.gguf
    sha256: 797b11d5c2110846efbc9dd64ae4c52b9f81d1f29bca054d849d82c220157cad
    uri: 
      https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF/resolve/main/vicuna-33b-coder.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__vicuna-33B-coder-GGUF__vicuna-33b-coder.Q4_K_M.gguf
  tags:
  - transformers
  - llama
  - code
  - arxiv:1910.09700
  - base_model:FelixChao/vicuna-33b-coder
  - license:other
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: vicuna-33b-coder.Q4_K_S.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/vicuna-33B-coder-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: vicuna-33b-coder.Q4_K_S.gguf
    sha256: 0536bcb35d849fa8a395c8a5ce660e938f0bfa27e3572d5637d8fd6cead518d6
    uri: 
      https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF/resolve/main/vicuna-33b-coder.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__vicuna-33B-coder-GGUF__vicuna-33b-coder.Q4_K_S.gguf
  tags:
  - transformers
  - llama
  - code
  - arxiv:1910.09700
  - base_model:FelixChao/vicuna-33b-coder
  - license:other
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: vicuna-33b-coder.Q5_0.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/vicuna-33B-coder-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: vicuna-33b-coder.Q5_0.gguf
    sha256: ff28ee072591931a038b0ed239d949ed0015a6aa849ac692359548ced664d2fe
    uri: 
      https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF/resolve/main/vicuna-33b-coder.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__vicuna-33B-coder-GGUF__vicuna-33b-coder.Q5_0.gguf
  tags:
  - transformers
  - llama
  - code
  - arxiv:1910.09700
  - base_model:FelixChao/vicuna-33b-coder
  - license:other
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: vicuna-33b-coder.Q5_K_M.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/vicuna-33B-coder-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: vicuna-33b-coder.Q5_K_M.gguf
    sha256: 5010c8b5fca91cceb1436e0821ec1f745cf12a1112418398ef25c7d5b709291b
    uri: 
      https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF/resolve/main/vicuna-33b-coder.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__vicuna-33B-coder-GGUF__vicuna-33b-coder.Q5_K_M.gguf
  tags:
  - transformers
  - llama
  - code
  - arxiv:1910.09700
  - base_model:FelixChao/vicuna-33b-coder
  - license:other
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: vicuna-33b-coder.Q5_K_S.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/vicuna-33B-coder-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: vicuna-33b-coder.Q5_K_S.gguf
    sha256: 024ba8562721058e7d551c50e91c9fe5822ba6e3106e65f057c31c4c7ceedf57
    uri: 
      https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF/resolve/main/vicuna-33b-coder.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__vicuna-33B-coder-GGUF__vicuna-33b-coder.Q5_K_S.gguf
  tags:
  - transformers
  - llama
  - code
  - arxiv:1910.09700
  - base_model:FelixChao/vicuna-33b-coder
  - license:other
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: vicuna-33b-coder.Q6_K.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/vicuna-33B-coder-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: vicuna-33b-coder.Q6_K.gguf
    sha256: 760ef3cf54ef11e6a1e9e1f19cea27f5b6891eab60ee1e93b97143212838e77e
    uri: 
      https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF/resolve/main/vicuna-33b-coder.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__vicuna-33B-coder-GGUF__vicuna-33b-coder.Q6_K.gguf
  tags:
  - transformers
  - llama
  - code
  - arxiv:1910.09700
  - base_model:FelixChao/vicuna-33b-coder
  - license:other
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: vicuna-33b-coder.Q8_0.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/vicuna-33B-coder-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: vicuna-33b-coder.Q8_0.gguf
    sha256: be78ac130b6400139d2bace0516f4b46c508d9987e7e8a87988d555a90162558
    uri: 
      https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF/resolve/main/vicuna-33b-coder.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__vicuna-33B-coder-GGUF__vicuna-33b-coder.Q8_0.gguf
  tags:
  - transformers
  - llama
  - code
  - arxiv:1910.09700
  - base_model:FelixChao/vicuna-33b-coder
  - license:other
  - model-index
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/vicuna-33B-coder-GGUF
