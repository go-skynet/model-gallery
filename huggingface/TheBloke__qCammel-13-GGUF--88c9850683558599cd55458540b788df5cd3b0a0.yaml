- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q2_K.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q2_K.gguf
    sha256: 1053c2f63fc0d2d0de8a88209b011a4564f79077f0d6636a24bb2ea19aec85d0
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q2_K.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q3_K_L.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q3_K_L.gguf
    sha256: 35b14f68fffd141db639696378348c74228f9033be90ff1c237573ab29f98347
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q3_K_L.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q3_K_M.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q3_K_M.gguf
    sha256: 5ba67d9852a525974c3910d7fb94ca0d6612e1d20f97831ad4deaa289abf8d9d
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q3_K_M.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q3_K_S.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q3_K_S.gguf
    sha256: 8937f9a370a3a1787c1dd7319b142cfa7cd602827dd3070567ef6781c4da3303
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q3_K_S.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q4_0.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q4_0.gguf
    sha256: e8467f436e3bfaa96b8cc8a6ff3b21559219e69c1e5cdfa5fb0ca3da5264ec71
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q4_0.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q4_K_M.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q4_K_M.gguf
    sha256: 536c995e353e4b75f81694a092bb24f64229d43300dd6ccf4c75533c4685d7d0
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q4_K_M.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q4_K_S.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q4_K_S.gguf
    sha256: 7e94e46702920a58b8cd60f53e0fe18665b83381570c1266e1a99522eb095db9
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q4_K_S.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q5_0.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q5_0.gguf
    sha256: 2d486c6d31ff7a29a73b4655e66dbf78a9317f7eb893cd592f1603a34df10c2a
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q5_0.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q5_K_M.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q5_K_M.gguf
    sha256: 7329b36bda404b8bf6721f37b6d8adeb697424e31ac1bcb1f8ed9147621e7468
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q5_K_M.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q5_K_S.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q5_K_S.gguf
    sha256: 5c78ac764427894198738b18264b5657e82842794254d6fc0961ac43441c7905
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q5_K_S.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q6_K.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q6_K.gguf
    sha256: cdb191be2429808844d9abab87a198efe8f9f5ff2662491a14874391f4bcdc57
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q6_K.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q8_0.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llama configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q8_0.gguf
    sha256: d77225cdd0b1dc084ebd35d891d39273b9900eac6742f4dde8a8e4cf7ebdf4ac
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q8_0.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q2_K.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q2_K.gguf
    sha256: 1053c2f63fc0d2d0de8a88209b011a4564f79077f0d6636a24bb2ea19aec85d0
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q2_K.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q3_K_L.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q3_K_L.gguf
    sha256: 35b14f68fffd141db639696378348c74228f9033be90ff1c237573ab29f98347
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q3_K_L.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q3_K_M.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q3_K_M.gguf
    sha256: 5ba67d9852a525974c3910d7fb94ca0d6612e1d20f97831ad4deaa289abf8d9d
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q3_K_M.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q3_K_S.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q3_K_S.gguf
    sha256: 8937f9a370a3a1787c1dd7319b142cfa7cd602827dd3070567ef6781c4da3303
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q3_K_S.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q4_0.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q4_0.gguf
    sha256: e8467f436e3bfaa96b8cc8a6ff3b21559219e69c1e5cdfa5fb0ca3da5264ec71
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q4_0.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q4_K_M.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q4_K_M.gguf
    sha256: 536c995e353e4b75f81694a092bb24f64229d43300dd6ccf4c75533c4685d7d0
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q4_K_M.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q4_K_S.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q4_K_S.gguf
    sha256: 7e94e46702920a58b8cd60f53e0fe18665b83381570c1266e1a99522eb095db9
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q4_K_S.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q5_0.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q5_0.gguf
    sha256: 2d486c6d31ff7a29a73b4655e66dbf78a9317f7eb893cd592f1603a34df10c2a
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q5_0.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q5_K_M.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q5_K_M.gguf
    sha256: 7329b36bda404b8bf6721f37b6d8adeb697424e31ac1bcb1f8ed9147621e7468
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q5_K_M.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q5_K_S.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q5_K_S.gguf
    sha256: 5c78ac764427894198738b18264b5657e82842794254d6fc0961ac43441c7905
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q5_K_S.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q6_K.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q6_K.gguf
    sha256: cdb191be2429808844d9abab87a198efe8f9f5ff2662491a14874391f4bcdc57
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q6_K.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: qcammel-13.Q8_0.gguf
    template:
      chat: Vicuna
      completion: Vicuna
  description: TheBloke/qCammel-13-GGUF - llamaFallback configuration
  files:
  - filename: Vicuna.tmpl
    sha256: e4f62a2354991f17f4da27228ce9416adc416db370ee9fbb8f4d114ed014a221
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Vicuna.tmpl
  - filename: qcammel-13.Q8_0.gguf
    sha256: d77225cdd0b1dc084ebd35d891d39273b9900eac6742f4dde8a8e4cf7ebdf4ac
    uri: 
      https://huggingface.co/TheBloke/qCammel-13-GGUF/resolve/main/qcammel-13.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__qCammel-13-GGUF__qcammel-13.Q8_0.gguf
  tags:
  - transformers
  - llama
  - pytorch
  - llama-2
  - qCammel-13
  - text-generation
  - en
  - arxiv:2305.12031
  - arxiv:2305.14314
  - arxiv:2302.13971
  - base_model:augtoma/qCammel-13
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/qCammel-13-GGUF
