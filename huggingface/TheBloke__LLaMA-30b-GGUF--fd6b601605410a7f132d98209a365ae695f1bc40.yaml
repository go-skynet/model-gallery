- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-30b.Q2_K.gguf
    template:
      chat: TheBloke__LLaMA-30b-GGUF
      completion: TheBloke__LLaMA-30b-GGUF
  description: TheBloke/LLaMA-30b-GGUF - llama configuration
  files:
  - filename: TheBloke__LLaMA-30b-GGUF.tmpl
    sha256: b1ea7f3b90b87ed8a88b3936b3ff1d5d69829debc137df3bdb4933e2b8688c56
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/TheBloke__LLaMA-30b-GGUF.tmpl
  - filename: llama-30b.Q2_K.gguf
    sha256: 3d12653f16fd8c7d4ae7430991a0a41eb9f808b60d912e0f6f4db5f675b4f153
    uri: https://huggingface.co/TheBloke/LLaMA-30b-GGUF/resolve/main/llama-30b.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__LLaMA-30b-GGUF__llama-30b.Q2_K.gguf
  tags:
  - transformers
  - llama
  - base_model:https://ai.meta.com/blog/large-language-model-llama-meta-ai
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/LLaMA-30b-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-30b.Q3_K_L.gguf
    template:
      chat: TheBloke__LLaMA-30b-GGUF
      completion: TheBloke__LLaMA-30b-GGUF
  description: TheBloke/LLaMA-30b-GGUF - llama configuration
  files:
  - filename: TheBloke__LLaMA-30b-GGUF.tmpl
    sha256: b1ea7f3b90b87ed8a88b3936b3ff1d5d69829debc137df3bdb4933e2b8688c56
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/TheBloke__LLaMA-30b-GGUF.tmpl
  - filename: llama-30b.Q3_K_L.gguf
    sha256: d651b9d0f1a8e56abe39f7c9b6827c62fa3272357758f3712bc7d2bb8b939d3f
    uri: 
      https://huggingface.co/TheBloke/LLaMA-30b-GGUF/resolve/main/llama-30b.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__LLaMA-30b-GGUF__llama-30b.Q3_K_L.gguf
  tags:
  - transformers
  - llama
  - base_model:https://ai.meta.com/blog/large-language-model-llama-meta-ai
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/LLaMA-30b-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-30b.Q3_K_M.gguf
    template:
      chat: TheBloke__LLaMA-30b-GGUF
      completion: TheBloke__LLaMA-30b-GGUF
  description: TheBloke/LLaMA-30b-GGUF - llama configuration
  files:
  - filename: TheBloke__LLaMA-30b-GGUF.tmpl
    sha256: b1ea7f3b90b87ed8a88b3936b3ff1d5d69829debc137df3bdb4933e2b8688c56
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/TheBloke__LLaMA-30b-GGUF.tmpl
  - filename: llama-30b.Q3_K_M.gguf
    sha256: 519bb7675ae7165146836cbf797e1e95d5017e30858a8c7f6676dedb4857ec9d
    uri: 
      https://huggingface.co/TheBloke/LLaMA-30b-GGUF/resolve/main/llama-30b.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__LLaMA-30b-GGUF__llama-30b.Q3_K_M.gguf
  tags:
  - transformers
  - llama
  - base_model:https://ai.meta.com/blog/large-language-model-llama-meta-ai
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/LLaMA-30b-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-30b.Q3_K_S.gguf
    template:
      chat: TheBloke__LLaMA-30b-GGUF
      completion: TheBloke__LLaMA-30b-GGUF
  description: TheBloke/LLaMA-30b-GGUF - llama configuration
  files:
  - filename: TheBloke__LLaMA-30b-GGUF.tmpl
    sha256: b1ea7f3b90b87ed8a88b3936b3ff1d5d69829debc137df3bdb4933e2b8688c56
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/TheBloke__LLaMA-30b-GGUF.tmpl
  - filename: llama-30b.Q3_K_S.gguf
    sha256: c0014dc2831c47b340d84b16bd0bd6e6330fd354d074b3a35a9dedcd021ab37e
    uri: 
      https://huggingface.co/TheBloke/LLaMA-30b-GGUF/resolve/main/llama-30b.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__LLaMA-30b-GGUF__llama-30b.Q3_K_S.gguf
  tags:
  - transformers
  - llama
  - base_model:https://ai.meta.com/blog/large-language-model-llama-meta-ai
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/LLaMA-30b-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-30b.Q4_0.gguf
    template:
      chat: TheBloke__LLaMA-30b-GGUF
      completion: TheBloke__LLaMA-30b-GGUF
  description: TheBloke/LLaMA-30b-GGUF - llama configuration
  files:
  - filename: TheBloke__LLaMA-30b-GGUF.tmpl
    sha256: b1ea7f3b90b87ed8a88b3936b3ff1d5d69829debc137df3bdb4933e2b8688c56
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/TheBloke__LLaMA-30b-GGUF.tmpl
  - filename: llama-30b.Q4_0.gguf
    sha256: beeb177972a24d31ce240eb26ae1f014e2bc1c37d695441173727b6056654b4b
    uri: https://huggingface.co/TheBloke/LLaMA-30b-GGUF/resolve/main/llama-30b.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__LLaMA-30b-GGUF__llama-30b.Q4_0.gguf
  tags:
  - transformers
  - llama
  - base_model:https://ai.meta.com/blog/large-language-model-llama-meta-ai
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/LLaMA-30b-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-30b.Q4_K_M.gguf
    template:
      chat: TheBloke__LLaMA-30b-GGUF
      completion: TheBloke__LLaMA-30b-GGUF
  description: TheBloke/LLaMA-30b-GGUF - llama configuration
  files:
  - filename: TheBloke__LLaMA-30b-GGUF.tmpl
    sha256: b1ea7f3b90b87ed8a88b3936b3ff1d5d69829debc137df3bdb4933e2b8688c56
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/TheBloke__LLaMA-30b-GGUF.tmpl
  - filename: llama-30b.Q4_K_M.gguf
    sha256: 2f91e4d96ba527fcba5bfd25149969e5d9da0e751e8102d4e5e79e26d1e39d31
    uri: 
      https://huggingface.co/TheBloke/LLaMA-30b-GGUF/resolve/main/llama-30b.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__LLaMA-30b-GGUF__llama-30b.Q4_K_M.gguf
  tags:
  - transformers
  - llama
  - base_model:https://ai.meta.com/blog/large-language-model-llama-meta-ai
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/LLaMA-30b-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-30b.Q4_K_S.gguf
    template:
      chat: TheBloke__LLaMA-30b-GGUF
      completion: TheBloke__LLaMA-30b-GGUF
  description: TheBloke/LLaMA-30b-GGUF - llama configuration
  files:
  - filename: TheBloke__LLaMA-30b-GGUF.tmpl
    sha256: b1ea7f3b90b87ed8a88b3936b3ff1d5d69829debc137df3bdb4933e2b8688c56
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/TheBloke__LLaMA-30b-GGUF.tmpl
  - filename: llama-30b.Q4_K_S.gguf
    sha256: a234580e71077fcde84aac166b86211828802d2017a93aac6ec27fc9c0a6dbf1
    uri: 
      https://huggingface.co/TheBloke/LLaMA-30b-GGUF/resolve/main/llama-30b.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__LLaMA-30b-GGUF__llama-30b.Q4_K_S.gguf
  tags:
  - transformers
  - llama
  - base_model:https://ai.meta.com/blog/large-language-model-llama-meta-ai
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/LLaMA-30b-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-30b.Q5_0.gguf
    template:
      chat: TheBloke__LLaMA-30b-GGUF
      completion: TheBloke__LLaMA-30b-GGUF
  description: TheBloke/LLaMA-30b-GGUF - llama configuration
  files:
  - filename: TheBloke__LLaMA-30b-GGUF.tmpl
    sha256: b1ea7f3b90b87ed8a88b3936b3ff1d5d69829debc137df3bdb4933e2b8688c56
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/TheBloke__LLaMA-30b-GGUF.tmpl
  - filename: llama-30b.Q5_0.gguf
    sha256: a80bbac2747a6cf4d0ab2c2129405e27ab1143299ade89cd5593a4a792145ba5
    uri: https://huggingface.co/TheBloke/LLaMA-30b-GGUF/resolve/main/llama-30b.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__LLaMA-30b-GGUF__llama-30b.Q5_0.gguf
  tags:
  - transformers
  - llama
  - base_model:https://ai.meta.com/blog/large-language-model-llama-meta-ai
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/LLaMA-30b-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-30b.Q5_K_M.gguf
    template:
      chat: TheBloke__LLaMA-30b-GGUF
      completion: TheBloke__LLaMA-30b-GGUF
  description: TheBloke/LLaMA-30b-GGUF - llama configuration
  files:
  - filename: TheBloke__LLaMA-30b-GGUF.tmpl
    sha256: b1ea7f3b90b87ed8a88b3936b3ff1d5d69829debc137df3bdb4933e2b8688c56
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/TheBloke__LLaMA-30b-GGUF.tmpl
  - filename: llama-30b.Q5_K_M.gguf
    sha256: 068f4e97c62d02b8a5c71675b9f33e8fca9d1baa6d9c45ecb354df14d0d679b0
    uri: 
      https://huggingface.co/TheBloke/LLaMA-30b-GGUF/resolve/main/llama-30b.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__LLaMA-30b-GGUF__llama-30b.Q5_K_M.gguf
  tags:
  - transformers
  - llama
  - base_model:https://ai.meta.com/blog/large-language-model-llama-meta-ai
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/LLaMA-30b-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-30b.Q5_K_S.gguf
    template:
      chat: TheBloke__LLaMA-30b-GGUF
      completion: TheBloke__LLaMA-30b-GGUF
  description: TheBloke/LLaMA-30b-GGUF - llama configuration
  files:
  - filename: TheBloke__LLaMA-30b-GGUF.tmpl
    sha256: b1ea7f3b90b87ed8a88b3936b3ff1d5d69829debc137df3bdb4933e2b8688c56
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/TheBloke__LLaMA-30b-GGUF.tmpl
  - filename: llama-30b.Q5_K_S.gguf
    sha256: 961cb2f5ddc7bb49741ea8ad740e0ad6a193739cf3e59a4c176b3f0951cb66bc
    uri: 
      https://huggingface.co/TheBloke/LLaMA-30b-GGUF/resolve/main/llama-30b.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__LLaMA-30b-GGUF__llama-30b.Q5_K_S.gguf
  tags:
  - transformers
  - llama
  - base_model:https://ai.meta.com/blog/large-language-model-llama-meta-ai
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/LLaMA-30b-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-30b.Q6_K.gguf
    template:
      chat: TheBloke__LLaMA-30b-GGUF
      completion: TheBloke__LLaMA-30b-GGUF
  description: TheBloke/LLaMA-30b-GGUF - llama configuration
  files:
  - filename: TheBloke__LLaMA-30b-GGUF.tmpl
    sha256: b1ea7f3b90b87ed8a88b3936b3ff1d5d69829debc137df3bdb4933e2b8688c56
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/TheBloke__LLaMA-30b-GGUF.tmpl
  - filename: llama-30b.Q6_K.gguf
    sha256: 9fcad3fb06326629ac5372ca37268f7b1cb24ced7ada0b58555ddd40134ee871
    uri: https://huggingface.co/TheBloke/LLaMA-30b-GGUF/resolve/main/llama-30b.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__LLaMA-30b-GGUF__llama-30b.Q6_K.gguf
  tags:
  - transformers
  - llama
  - base_model:https://ai.meta.com/blog/large-language-model-llama-meta-ai
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/LLaMA-30b-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-30b.Q8_0.gguf
    template:
      chat: TheBloke__LLaMA-30b-GGUF
      completion: TheBloke__LLaMA-30b-GGUF
  description: TheBloke/LLaMA-30b-GGUF - llama configuration
  files:
  - filename: TheBloke__LLaMA-30b-GGUF.tmpl
    sha256: b1ea7f3b90b87ed8a88b3936b3ff1d5d69829debc137df3bdb4933e2b8688c56
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/TheBloke__LLaMA-30b-GGUF.tmpl
  - filename: llama-30b.Q8_0.gguf
    sha256: d066fea7c1b4cf87fb55a0492930538e2b64dcada355d4a008d2ea780b163ca0
    uri: https://huggingface.co/TheBloke/LLaMA-30b-GGUF/resolve/main/llama-30b.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: other
  name: TheBloke__LLaMA-30b-GGUF__llama-30b.Q8_0.gguf
  tags:
  - transformers
  - llama
  - base_model:https://ai.meta.com/blog/large-language-model-llama-meta-ai
  - license:other
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/LLaMA-30b-GGUF
