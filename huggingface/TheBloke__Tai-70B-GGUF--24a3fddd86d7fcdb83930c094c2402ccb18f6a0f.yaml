- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: tai-70b.Q2_K.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Tai-70B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: tai-70b.Q2_K.gguf
    sha256: e052022faf55cfd48f39ffccd1c2fd7820cfca21411a5d6fc2fdafebf92a6dfc
    uri: https://huggingface.co/TheBloke/Tai-70B-GGUF/resolve/main/tai-70b.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Tai-70B-GGUF__tai-70b.Q2_K.gguf
  tags:
  - transformers
  - llama
  - base_model:Metaspectral/Tai
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Tai-70B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: tai-70b.Q3_K_L.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Tai-70B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: tai-70b.Q3_K_L.gguf
    sha256: 4074b500a0869b3a1cc72a1964b5477012ab875c58e0c25dde3c4b01ae1449ef
    uri: https://huggingface.co/TheBloke/Tai-70B-GGUF/resolve/main/tai-70b.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Tai-70B-GGUF__tai-70b.Q3_K_L.gguf
  tags:
  - transformers
  - llama
  - base_model:Metaspectral/Tai
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Tai-70B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: tai-70b.Q3_K_M.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Tai-70B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: tai-70b.Q3_K_M.gguf
    sha256: c7aa865988089b28e5a9a015ca90ed71937504fe641c22c4bf6bd801591bee77
    uri: https://huggingface.co/TheBloke/Tai-70B-GGUF/resolve/main/tai-70b.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Tai-70B-GGUF__tai-70b.Q3_K_M.gguf
  tags:
  - transformers
  - llama
  - base_model:Metaspectral/Tai
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Tai-70B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: tai-70b.Q3_K_S.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Tai-70B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: tai-70b.Q3_K_S.gguf
    sha256: d7eec019832e9007954328743135366336aba173ebc326628d1a19b57e3faca9
    uri: https://huggingface.co/TheBloke/Tai-70B-GGUF/resolve/main/tai-70b.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Tai-70B-GGUF__tai-70b.Q3_K_S.gguf
  tags:
  - transformers
  - llama
  - base_model:Metaspectral/Tai
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Tai-70B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: tai-70b.Q4_0.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Tai-70B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: tai-70b.Q4_0.gguf
    sha256: 7270d2c901c687b1380f25708d4dde646a51659d40a6d8133d67cfa3b6d2af77
    uri: https://huggingface.co/TheBloke/Tai-70B-GGUF/resolve/main/tai-70b.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Tai-70B-GGUF__tai-70b.Q4_0.gguf
  tags:
  - transformers
  - llama
  - base_model:Metaspectral/Tai
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Tai-70B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: tai-70b.Q4_K_M.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Tai-70B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: tai-70b.Q4_K_M.gguf
    sha256: ea34452192ef10ee8fc1e3a2a40a2a5d08cb879740db5ceeba3beec12a0da2b4
    uri: https://huggingface.co/TheBloke/Tai-70B-GGUF/resolve/main/tai-70b.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Tai-70B-GGUF__tai-70b.Q4_K_M.gguf
  tags:
  - transformers
  - llama
  - base_model:Metaspectral/Tai
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Tai-70B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: tai-70b.Q4_K_S.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Tai-70B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: tai-70b.Q4_K_S.gguf
    sha256: 8ec01a480a89a0b647a3d0acc4ef7b3f269fc13cfc5ff35260730f6ceb7afc84
    uri: https://huggingface.co/TheBloke/Tai-70B-GGUF/resolve/main/tai-70b.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Tai-70B-GGUF__tai-70b.Q4_K_S.gguf
  tags:
  - transformers
  - llama
  - base_model:Metaspectral/Tai
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Tai-70B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: tai-70b.Q5_0.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Tai-70B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: tai-70b.Q5_0.gguf
    sha256: 686dfaec7c9a4e5e39af7025b5d8cb566a7992d820cf39a4e660d261a394f09e
    uri: https://huggingface.co/TheBloke/Tai-70B-GGUF/resolve/main/tai-70b.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Tai-70B-GGUF__tai-70b.Q5_0.gguf
  tags:
  - transformers
  - llama
  - base_model:Metaspectral/Tai
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Tai-70B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: tai-70b.Q5_K_M.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Tai-70B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: tai-70b.Q5_K_M.gguf
    sha256: abc152d4601062764108943f5ebfb7c2f43bb184f5729e160f328997a0e2b0eb
    uri: https://huggingface.co/TheBloke/Tai-70B-GGUF/resolve/main/tai-70b.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Tai-70B-GGUF__tai-70b.Q5_K_M.gguf
  tags:
  - transformers
  - llama
  - base_model:Metaspectral/Tai
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Tai-70B-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: tai-70b.Q5_K_S.gguf
    template:
      chat: Orca-Vicuna
      completion: Orca-Vicuna
  description: TheBloke/Tai-70B-GGUF - llama configuration
  files:
  - filename: Orca-Vicuna.tmpl
    sha256: 075f13184a2f3b1abf633f04395bfb9fa859e954c72624376866eb65bbcfb8f3
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Orca-Vicuna.tmpl
  - filename: tai-70b.Q5_K_S.gguf
    sha256: c21312281e62c0cec690db552a8bc9e713db67dbb9448c10a1bc8a19899edf04
    uri: https://huggingface.co/TheBloke/Tai-70B-GGUF/resolve/main/tai-70b.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Tai-70B-GGUF__tai-70b.Q5_K_S.gguf
  tags:
  - transformers
  - llama
  - base_model:Metaspectral/Tai
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Tai-70B-GGUF
