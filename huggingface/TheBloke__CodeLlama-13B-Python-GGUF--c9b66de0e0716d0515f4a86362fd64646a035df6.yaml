---
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-13b-python.Q2_K.gguf
    template:
      ? - chat
      : CodeLlama.tmpl
      ? - completion
      : CodeLlama.tmpl
  description: TheBloke/CodeLlama-13B-Python-GGUF - llama configuration
  files:
  - filename: CodeLlama.tmpl
    sha256: e3d5d5e1b39fca7445ffe9e8285ce48bbae9f4faac6667562dba6de2a6bb0efd
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/CodeLlama.tmpl
  - filename: codellama-13b-python.Q2_K.gguf
    sha256: afb785bb87a99e74cd0fcf6c3afc8edb3ca03b7bb2f976331d154d82c5b012c5
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF/resolve/main/codellama-13b-python.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__CodeLlama-13B-Python-GGUF__codellama-13b-python.Q2_K.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-13b-python.Q3_K_L.gguf
    template:
      ? - chat
      : CodeLlama.tmpl
      ? - completion
      : CodeLlama.tmpl
  description: TheBloke/CodeLlama-13B-Python-GGUF - llama configuration
  files:
  - filename: CodeLlama.tmpl
    sha256: e3d5d5e1b39fca7445ffe9e8285ce48bbae9f4faac6667562dba6de2a6bb0efd
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/CodeLlama.tmpl
  - filename: codellama-13b-python.Q3_K_L.gguf
    sha256: 1c5b9eb74551df1072597b706df4494421c3fd6780815a48b15bfccd00984821
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF/resolve/main/codellama-13b-python.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__CodeLlama-13B-Python-GGUF__codellama-13b-python.Q3_K_L.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-13b-python.Q3_K_M.gguf
    template:
      ? - chat
      : CodeLlama.tmpl
      ? - completion
      : CodeLlama.tmpl
  description: TheBloke/CodeLlama-13B-Python-GGUF - llama configuration
  files:
  - filename: CodeLlama.tmpl
    sha256: e3d5d5e1b39fca7445ffe9e8285ce48bbae9f4faac6667562dba6de2a6bb0efd
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/CodeLlama.tmpl
  - filename: codellama-13b-python.Q3_K_M.gguf
    sha256: 9a80359cad467fbeabf09534a6c68cf8eb4246abf25ac58a01874028f4040a3f
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF/resolve/main/codellama-13b-python.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__CodeLlama-13B-Python-GGUF__codellama-13b-python.Q3_K_M.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-13b-python.Q3_K_S.gguf
    template:
      ? - chat
      : CodeLlama.tmpl
      ? - completion
      : CodeLlama.tmpl
  description: TheBloke/CodeLlama-13B-Python-GGUF - llama configuration
  files:
  - filename: CodeLlama.tmpl
    sha256: e3d5d5e1b39fca7445ffe9e8285ce48bbae9f4faac6667562dba6de2a6bb0efd
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/CodeLlama.tmpl
  - filename: codellama-13b-python.Q3_K_S.gguf
    sha256: 4c3b12ebdb06e56498afb7f614cf33809291702309d2e94d7a268c0bddec2152
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF/resolve/main/codellama-13b-python.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__CodeLlama-13B-Python-GGUF__codellama-13b-python.Q3_K_S.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-13b-python.Q4_0.gguf
    template:
      ? - chat
      : CodeLlama.tmpl
      ? - completion
      : CodeLlama.tmpl
  description: TheBloke/CodeLlama-13B-Python-GGUF - llama configuration
  files:
  - filename: CodeLlama.tmpl
    sha256: e3d5d5e1b39fca7445ffe9e8285ce48bbae9f4faac6667562dba6de2a6bb0efd
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/CodeLlama.tmpl
  - filename: codellama-13b-python.Q4_0.gguf
    sha256: 17cf38ee9d7d81d050305fdee425d51039f1f2f905b03fab26fa52d0acb0965f
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF/resolve/main/codellama-13b-python.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__CodeLlama-13B-Python-GGUF__codellama-13b-python.Q4_0.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-13b-python.Q4_K_M.gguf
    template:
      ? - chat
      : CodeLlama.tmpl
      ? - completion
      : CodeLlama.tmpl
  description: TheBloke/CodeLlama-13B-Python-GGUF - llama configuration
  files:
  - filename: CodeLlama.tmpl
    sha256: e3d5d5e1b39fca7445ffe9e8285ce48bbae9f4faac6667562dba6de2a6bb0efd
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/CodeLlama.tmpl
  - filename: codellama-13b-python.Q4_K_M.gguf
    sha256: fa2af128c4a793f17d8ae7e6f042f29c3a957a917207dcc2679e0b81607ecbb0
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF/resolve/main/codellama-13b-python.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__CodeLlama-13B-Python-GGUF__codellama-13b-python.Q4_K_M.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-13b-python.Q4_K_S.gguf
    template:
      ? - chat
      : CodeLlama.tmpl
      ? - completion
      : CodeLlama.tmpl
  description: TheBloke/CodeLlama-13B-Python-GGUF - llama configuration
  files:
  - filename: CodeLlama.tmpl
    sha256: e3d5d5e1b39fca7445ffe9e8285ce48bbae9f4faac6667562dba6de2a6bb0efd
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/CodeLlama.tmpl
  - filename: codellama-13b-python.Q4_K_S.gguf
    sha256: 6227b15c018f39a4b8f57ff2217fc29a5c9979063040d4d1ff831abc81d039e9
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF/resolve/main/codellama-13b-python.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__CodeLlama-13B-Python-GGUF__codellama-13b-python.Q4_K_S.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-13b-python.Q5_0.gguf
    template:
      ? - chat
      : CodeLlama.tmpl
      ? - completion
      : CodeLlama.tmpl
  description: TheBloke/CodeLlama-13B-Python-GGUF - llama configuration
  files:
  - filename: CodeLlama.tmpl
    sha256: e3d5d5e1b39fca7445ffe9e8285ce48bbae9f4faac6667562dba6de2a6bb0efd
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/CodeLlama.tmpl
  - filename: codellama-13b-python.Q5_0.gguf
    sha256: 90b09e8c2cbde45c22d48104381bfe3097748150c7e2a2c87b60c39a2980e70b
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF/resolve/main/codellama-13b-python.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__CodeLlama-13B-Python-GGUF__codellama-13b-python.Q5_0.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-13b-python.Q5_K_M.gguf
    template:
      ? - chat
      : CodeLlama.tmpl
      ? - completion
      : CodeLlama.tmpl
  description: TheBloke/CodeLlama-13B-Python-GGUF - llama configuration
  files:
  - filename: CodeLlama.tmpl
    sha256: e3d5d5e1b39fca7445ffe9e8285ce48bbae9f4faac6667562dba6de2a6bb0efd
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/CodeLlama.tmpl
  - filename: codellama-13b-python.Q5_K_M.gguf
    sha256: 42e83db1e98c43101d4a67fa8948f862189e1199c19f215a095349e8ec86d025
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF/resolve/main/codellama-13b-python.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__CodeLlama-13B-Python-GGUF__codellama-13b-python.Q5_K_M.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-13b-python.Q5_K_S.gguf
    template:
      ? - chat
      : CodeLlama.tmpl
      ? - completion
      : CodeLlama.tmpl
  description: TheBloke/CodeLlama-13B-Python-GGUF - llama configuration
  files:
  - filename: CodeLlama.tmpl
    sha256: e3d5d5e1b39fca7445ffe9e8285ce48bbae9f4faac6667562dba6de2a6bb0efd
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/CodeLlama.tmpl
  - filename: codellama-13b-python.Q5_K_S.gguf
    sha256: 592f7062279d5c2202d4147d29d53383d8704ec993a811ff5a6a1f5797b54ec6
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF/resolve/main/codellama-13b-python.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__CodeLlama-13B-Python-GGUF__codellama-13b-python.Q5_K_S.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-13b-python.Q6_K.gguf
    template:
      ? - chat
      : CodeLlama.tmpl
      ? - completion
      : CodeLlama.tmpl
  description: TheBloke/CodeLlama-13B-Python-GGUF - llama configuration
  files:
  - filename: CodeLlama.tmpl
    sha256: e3d5d5e1b39fca7445ffe9e8285ce48bbae9f4faac6667562dba6de2a6bb0efd
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/CodeLlama.tmpl
  - filename: codellama-13b-python.Q6_K.gguf
    sha256: 1cfdd774a92c1e8224db8bcc4af31fe34fb9c5346d2f3e75ec14891ec11f5b4d
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF/resolve/main/codellama-13b-python.Q6_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__CodeLlama-13B-Python-GGUF__codellama-13b-python.Q6_K.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: codellama-13b-python.Q8_0.gguf
    template:
      ? - chat
      : CodeLlama.tmpl
      ? - completion
      : CodeLlama.tmpl
  description: TheBloke/CodeLlama-13B-Python-GGUF - llama configuration
  files:
  - filename: CodeLlama.tmpl
    sha256: e3d5d5e1b39fca7445ffe9e8285ce48bbae9f4faac6667562dba6de2a6bb0efd
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/CodeLlama.tmpl
  - filename: codellama-13b-python.Q8_0.gguf
    sha256: 39556aa95d5ec1be46571ff91a69beb168761f9d3dbdd775007cd23879971963
    uri: 
      https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF/resolve/main/codellama-13b-python.Q8_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__CodeLlama-13B-Python-GGUF__codellama-13b-python.Q8_0.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - text-generation
  - code
  - arxiv:2308.12950
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF
