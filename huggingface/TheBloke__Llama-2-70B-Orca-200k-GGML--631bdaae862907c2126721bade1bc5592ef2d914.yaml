- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q2_K.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q2_K.bin
    sha256: 5ad849ba82bc71fdf3eb637247673c83ab026dbb1d6f187cc9ce29455916a3e9
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q2_K.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q2_K.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q3_K_L.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q3_K_L.bin
    sha256: ef964e5e830f9a1eeae763e5dd40d131430f3d846c748541153ad531867e7ff1
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q3_K_L.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q3_K_L.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q3_K_M.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q3_K_M.bin
    sha256: 3a1578c947e68b101dfc55a495737fb22e9087c38f9cd742fdabd191a49e3cfa
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q3_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q3_K_M.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q3_K_S.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q3_K_S.bin
    sha256: be1fcc05e12ce866db297dda1410a75802c825b0907d37625c24c6b14ae229c1
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q3_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q3_K_S.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q4_0.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q4_0.bin
    sha256: 9b398fc67397309f832fcf21c36c339d8a7cbe6b2b321a63ef3d8d430d6c7f51
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q4_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q4_0.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q4_1.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q4_1.bin
    sha256: d53bb834270dcf19e840bfaf12eb31e098511e1d0f1df45dcb592a293ccdc4bf
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q4_1.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q4_1.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q4_K_M.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q4_K_M.bin
    sha256: ad42ca227e12c6c5f7dbcca662e9d040315cb841e378df15d860c7cc148ee77a
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q4_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q4_K_M.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q4_K_S.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q4_K_S.bin
    sha256: fdf3c2c9fe6917f698b0f754839ed1c690c922111fc6772af5c7f31148a8ff4a
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q4_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q4_K_S.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q5_0.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q5_0.bin
    sha256: 7552b11f4db6189c26116d1a72891a2a1949b2b4ee4a0ca286d36f145c27575e
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q5_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q5_0.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q5_1.z01
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q5_1.z01
    sha256: c46156098b68710a9be0b87aa283c16f79a1df9710a254a8ed9bb44d58208b38
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q5_1.z01
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q5_1.z01
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q5_1.zip
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q5_1.zip
    sha256: f8f605f95b00a35d2ce8d47560468f149c642171c95c6313c982572393745489
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q5_1.zip
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q5_1.zip
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q5_K_M.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q5_K_M.bin
    sha256: 0ec4e8e871b2a49d594cd6fc4cb9594c223ddebeb0f0f8d1357dc91b8fb1832f
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q5_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q5_K_M.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q5_K_S.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q5_K_S.bin
    sha256: 83af8409825371c10435108b803db3379b773cb33e9676326fcf420b9718d899
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q5_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q5_K_S.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q6_K.z01
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q6_K.z01
    sha256: 0e330992e07cb589d8fd542cf121a64e03edd64d921b08246a6b96998b6c5035
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q6_K.z01
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q6_K.z01
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q6_K.zip
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q6_K.zip
    sha256: 741d5773bbb7af503fe9b89be953f24ca9e906dccf177734b1a23668609a63b5
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q6_K.zip
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q6_K.zip
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q8_0.z01
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q8_0.z01
    sha256: 51deabd07fec7de71ffc17c207b60aebba9dcaa5a5fef2e8268c7006888d1d32
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q8_0.z01
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q8_0.z01
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q8_0.zip
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q8_0.zip
    sha256: 5f3bb01cbd1306206271a19a72be653873dfb8125a97713a8df86b7f63de1189
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q8_0.zip
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q8_0.zip
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q2_K.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llamaFallback configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q2_K.bin
    sha256: 5ad849ba82bc71fdf3eb637247673c83ab026dbb1d6f187cc9ce29455916a3e9
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q2_K.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q2_K.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q3_K_L.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llamaFallback configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q3_K_L.bin
    sha256: ef964e5e830f9a1eeae763e5dd40d131430f3d846c748541153ad531867e7ff1
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q3_K_L.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q3_K_L.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q3_K_M.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llamaFallback configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q3_K_M.bin
    sha256: 3a1578c947e68b101dfc55a495737fb22e9087c38f9cd742fdabd191a49e3cfa
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q3_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q3_K_M.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q3_K_S.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llamaFallback configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q3_K_S.bin
    sha256: be1fcc05e12ce866db297dda1410a75802c825b0907d37625c24c6b14ae229c1
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q3_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q3_K_S.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q4_0.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llamaFallback configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q4_0.bin
    sha256: 9b398fc67397309f832fcf21c36c339d8a7cbe6b2b321a63ef3d8d430d6c7f51
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q4_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q4_0.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q4_1.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llamaFallback configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q4_1.bin
    sha256: d53bb834270dcf19e840bfaf12eb31e098511e1d0f1df45dcb592a293ccdc4bf
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q4_1.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q4_1.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q4_K_M.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llamaFallback configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q4_K_M.bin
    sha256: ad42ca227e12c6c5f7dbcca662e9d040315cb841e378df15d860c7cc148ee77a
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q4_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q4_K_M.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q4_K_S.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llamaFallback configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q4_K_S.bin
    sha256: fdf3c2c9fe6917f698b0f754839ed1c690c922111fc6772af5c7f31148a8ff4a
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q4_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q4_K_S.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q5_0.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llamaFallback configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q5_0.bin
    sha256: 7552b11f4db6189c26116d1a72891a2a1949b2b4ee4a0ca286d36f145c27575e
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q5_0.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q5_0.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q5_1.z01
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llamaFallback configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q5_1.z01
    sha256: c46156098b68710a9be0b87aa283c16f79a1df9710a254a8ed9bb44d58208b38
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q5_1.z01
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q5_1.z01
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q5_1.zip
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llamaFallback configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q5_1.zip
    sha256: f8f605f95b00a35d2ce8d47560468f149c642171c95c6313c982572393745489
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q5_1.zip
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q5_1.zip
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q5_K_M.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llamaFallback configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q5_K_M.bin
    sha256: 0ec4e8e871b2a49d594cd6fc4cb9594c223ddebeb0f0f8d1357dc91b8fb1832f
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q5_K_M.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q5_K_M.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q5_K_S.bin
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llamaFallback configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q5_K_S.bin
    sha256: 83af8409825371c10435108b803db3379b773cb33e9676326fcf420b9718d899
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q5_K_S.bin
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q5_K_S.bin
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q6_K.z01
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llamaFallback configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q6_K.z01
    sha256: 0e330992e07cb589d8fd542cf121a64e03edd64d921b08246a6b96998b6c5035
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q6_K.z01
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q6_K.z01
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q6_K.zip
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llamaFallback configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q6_K.zip
    sha256: 741d5773bbb7af503fe9b89be953f24ca9e906dccf177734b1a23668609a63b5
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q6_K.zip
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q6_K.zip
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q8_0.z01
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llamaFallback configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q8_0.z01
    sha256: 51deabd07fec7de71ffc17c207b60aebba9dcaa5a5fef2e8268c7006888d1d32
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q8_0.z01
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q8_0.z01
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
- config_file:
    backend: llama-stable
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.ggmlv3.Q8_0.zip
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGML - llamaFallback configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/dave-gray101/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.ggmlv3.Q8_0.zip
    sha256: 5f3bb01cbd1306206271a19a72be653873dfb8125a97713a8df86b7f63de1189
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML/resolve/main/llama-2-70b-orca-200k.ggmlv3.Q8_0.zip
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGML__llama-2-70b-orca-200k.ggmlv3.Q8_0.zip
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - base_model:ddobokki/Llama-2-70b-orca-200k
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGML
